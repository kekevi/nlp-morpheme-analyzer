{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheme Lemmatizer\n",
    "\n",
    "The morpheme-lemmatizer is an additional model based on a morpheme-segmenter model that given a sequence of potential morpheme strings of one word, it will regularize the potential morpheme strings.\n",
    "\n",
    "Pipeline:\n",
    "1. input: word w\n",
    "2. word w --> morpheme list: m0, m1, ...\n",
    "3. for each morpheme $m_i$, encode as integer representation of characters\n",
    "4. feed characters into fnn\n",
    "5. get regularized morpheme\n",
    "6. applied to all morphemes in morpheme list --> regularized morphemes: f(m0), f(m1), ...\n",
    "\n",
    "where $f(m_i) \\in M$ and $M$ is the morpheme lexicon.\n",
    "\n",
    "For the sake of trying out different models, this will be an external layer to the morpheme segmenter and will be a FFN that takes up to $m$-long substrings + index of morpheme in word + length of word. However, this could easily be built on top of the morpheme segmenter model as another layer.\n",
    "\n",
    "Note that because of this separate structure, we must have the hyper parameter: **cutoff-probability**, which states that the segmenter must give at least the cutoff-probability in order to split the substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import gc\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "from collections import defaultdict\n",
    "from morphemes import Morphemes\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU') # idk why m1 needs this (https://stackoverflow.com/q/72441453)\n",
    "import keras\n",
    "from keras.utils import Sequence, pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.datasets import imdb\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import SimpleRNN, Dense, Activation, Input, LSTM, ReLU, Layer, LayerNormalization, MultiHeadAttention, Dropout, Embedding, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting morpheme lexicon\n",
    "morpheme_lexicon = set()\n",
    "morphemes_in = {} # word -> morpheme\n",
    "with open('./morphemes_files/morphemes_with_inflection.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for word, ssv_morphemes in reader:\n",
    "        morpheme_list = ssv_morphemes.split()\n",
    "        morphemes_in[word] = morpheme_list\n",
    "        morpheme_lexicon.update(morpheme_list)\n",
    "\n",
    "\n",
    "int_to_morpheme = list(morpheme_lexicon)\n",
    "morpheme_to_int = {m: i for i, m in enumerate(int_to_morpheme)}\n",
    "\n",
    "NULL_LETTER = '_'\n",
    "int_to_letter = [NULL_LETTER] + list(string.ascii_letters[0:26])\n",
    "letter_to_int = {l: i for i, l in enumerate(int_to_letter)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load morpheme segmenter\n",
    "segmenter_model = keras.models.load_model('./models/MorphemeSegmenter-Transformer')\n",
    "\n",
    "def embed_word(w, MAX_WORD_LEN = 50): # note MAX_WORD_LEN is a hyperparam of the segmenter_model\n",
    "    filled = [letter_to_int[l] for l in w if l in letter_to_int]\n",
    "    full = filled + [letter_to_int['_']]*(MAX_WORD_LEN-len(filled))\n",
    "    return np.array(full)\n",
    "\n",
    "def decode_pred(pred_vec, min_p = .1):\n",
    "    ordered_cuts = np.flip(np.argsort(pred_vec))\n",
    "    likely_cuts = [i for i in ordered_cuts if pred_vec[i] > min_p]\n",
    "    return likely_cuts\n",
    "\n",
    "def segment_morphemes(word, min_p = .1):\n",
    "    return decode_pred(segmenter_model.predict(np.array([embed_word(word)]))[0], min_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
